{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c965285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math, random, sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "from collections import deque\n",
    "import pickle as pickle\n",
    "\n",
    "from jtnn import *\n",
    "from auxiliaries import build_parser, set_random_seed\n",
    "import rdkit\n",
    "import json, os\n",
    "from rdkit import RDLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31e0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = RDLogger.logger() \n",
    "lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ae1c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/huang651/port-to-botorch/rafa-pred-model'\n",
    "json_path = (root+'/default_gen_args2.json')\n",
    "cmd_args = {'beta': 0.002, 'max_beta': 1.0}\n",
    "with open(json_path) as handle:\n",
    "    args = json.loads(handle.read())\n",
    "args.update(cmd_args)\n",
    "if 'seed' in args:\n",
    "    set_random_seed(args['seed'])\n",
    "else:\n",
    "    args['seed'] = set_random_seed()\n",
    "if 'save_dir' not in args:\n",
    "    args['save_dir'] = \"gen-{}-h{}-l{}-n{}-e{}-s{}\".format(\n",
    "        '2dmodel', args['hidden_size'], args['latent_size'],\n",
    "        args['num_layers'], args['epoch'], args['seed']\n",
    "    )\n",
    "args['cuda'] = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ebd613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(anneal_iter=40000, anneal_rate=0.9, batch_size=32, beta=0.002, clip_norm=50.0, cuda=True, depthG=3, depthT=20, epoch=150, hidden_size=450, kl_anneal_iter=2000, latent_size=4, load_epoch=0, lr=0.001, max_beta=1.0, n_out=1, num_layers=3, print_iter=100, save_dir='gen-2dmodel-h450-l4-n3-e150-s764396391', save_iter=5000, seed=764396391, target='homo', total_trials=50, use_activation=True, vocab='/home/huang651/port-to-botorch/rafa-pred-model/data/rafa/vocab.txt', warmup=20000)\n"
     ]
    }
   ],
   "source": [
    "# save model settings\n",
    "if not os.path.exists(args['save_dir']):\n",
    "    os.makedirs(args['save_dir'])\n",
    "dump_json_path = os.path.join(args['save_dir'], 'model.json')\n",
    "if not os.path.exists(dump_json_path):\n",
    "    with open(dump_json_path, \"w\") as fp:\n",
    "        json.dump(args, fp, sort_keys=True, indent=4)\n",
    "args = Namespace(**args)\n",
    "print(args)\n",
    "train_path = os.path.join(f'rafa-processed')\n",
    "device = 'cuda' if args.cuda else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28c57010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JTNNVAE(\n",
      "  (jtnn): JTNNEncoder(\n",
      "    (embedding): Embedding(43, 450)\n",
      "    (outputNN): Sequential(\n",
      "      (0): Linear(in_features=900, out_features=450, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (GRU): GraphGRU(\n",
      "      (W_z): Linear(in_features=900, out_features=450, bias=True)\n",
      "      (W_r): Linear(in_features=450, out_features=450, bias=False)\n",
      "      (U_r): Linear(in_features=450, out_features=450, bias=True)\n",
      "      (W_h): Linear(in_features=900, out_features=450, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): JTNNDecoder(\n",
      "    (embedding): Embedding(43, 450)\n",
      "    (W_z): Linear(in_features=900, out_features=450, bias=True)\n",
      "    (U_r): Linear(in_features=450, out_features=450, bias=False)\n",
      "    (W_r): Linear(in_features=450, out_features=450, bias=True)\n",
      "    (W_h): Linear(in_features=900, out_features=450, bias=True)\n",
      "    (W): Linear(in_features=452, out_features=450, bias=True)\n",
      "    (U): Linear(in_features=452, out_features=450, bias=True)\n",
      "    (U_i): Linear(in_features=900, out_features=450, bias=True)\n",
      "    (W_o): Linear(in_features=450, out_features=43, bias=True)\n",
      "    (U_o): Linear(in_features=450, out_features=1, bias=True)\n",
      "    (pred_loss): CrossEntropyLoss()\n",
      "    (stop_loss): BCEWithLogitsLoss()\n",
      "  )\n",
      "  (jtmpn): JTMPN(\n",
      "    (W_i): Linear(in_features=40, out_features=450, bias=False)\n",
      "    (W_h): Linear(in_features=450, out_features=450, bias=False)\n",
      "    (W_o): Linear(in_features=485, out_features=450, bias=True)\n",
      "  )\n",
      "  (mpn): MPN(\n",
      "    (W_i): Linear(in_features=50, out_features=450, bias=False)\n",
      "    (W_h): Linear(in_features=450, out_features=450, bias=False)\n",
      "    (W_o): Linear(in_features=489, out_features=450, bias=True)\n",
      "  )\n",
      "  (A_assm): Linear(in_features=2, out_features=450, bias=False)\n",
      "  (assm_loss): CrossEntropyLoss()\n",
      "  (T_mean): Linear(in_features=450, out_features=2, bias=True)\n",
      "  (T_var): Linear(in_features=450, out_features=2, bias=True)\n",
      "  (G_mean): Linear(in_features=450, out_features=2, bias=True)\n",
      "  (G_var): Linear(in_features=450, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab = [x.strip(\"\\r\\n \") for x in open(args.vocab)] \n",
    "vocab = Vocab(vocab)\n",
    "\n",
    "model = JTNNVAE(vocab, args)\n",
    "if args.cuda:\n",
    "    model = model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44d2392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #Params: 4599K\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    if param.dim() == 1:\n",
    "        nn.init.constant_(param, 0)\n",
    "    else:\n",
    "        nn.init.xavier_normal_(param)\n",
    "\n",
    "if args.load_epoch > 0:\n",
    "    model.load_state_dict(torch.load(args.save_dir + \"/model.iter-\" + str(args.load_epoch)))\n",
    "\n",
    "print((\"Model #Params: %dK\" % (sum([x.nelement() for x in model.parameters()]) / 1000,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bfed48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, args.anneal_rate)\n",
    "scheduler.step()\n",
    "\n",
    "param_norm = lambda m: math.sqrt(sum([p.norm().item() ** 2 for p in m.parameters()]))\n",
    "grad_norm = lambda m: math.sqrt(sum([p.grad.norm().item() ** 2 for p in m.parameters() if p.grad is not None]))\n",
    "\n",
    "total_step = args.load_epoch\n",
    "beta = args.beta\n",
    "meters = np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e06c0d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at epoch: 1\n",
      "[100] Beta: 0.002, KL: 107.29, Word: 54.82, Topo: 90.38, Assm: 94.34, PNorm: 97.32, GNorm: 38.25\n",
      "[200] Beta: 0.002, KL: 119.78, Word: 76.46, Topo: 97.70, Assm: 96.51, PNorm: 100.29, GNorm: 25.24\n",
      "[300] Beta: 0.002, KL: 109.79, Word: 79.78, Topo: 98.19, Assm: 96.33, PNorm: 102.55, GNorm: 24.44\n",
      "[400] Beta: 0.002, KL: 108.09, Word: 81.70, Topo: 98.67, Assm: 97.38, PNorm: 104.31, GNorm: 17.59\n",
      "Currently at epoch: 2\n",
      "[500] Beta: 0.002, KL: 102.16, Word: 82.79, Topo: 98.68, Assm: 97.02, PNorm: 106.26, GNorm: 22.44\n",
      "[600] Beta: 0.002, KL: 99.65, Word: 83.68, Topo: 98.81, Assm: 97.33, PNorm: 107.89, GNorm: 23.38\n",
      "[700] Beta: 0.002, KL: 97.66, Word: 84.18, Topo: 98.96, Assm: 96.77, PNorm: 109.25, GNorm: 12.73\n",
      "[800] Beta: 0.002, KL: 97.25, Word: 84.75, Topo: 98.83, Assm: 97.19, PNorm: 110.43, GNorm: 31.14\n",
      "Currently at epoch: 3\n",
      "[900] Beta: 0.002, KL: 92.50, Word: 85.06, Topo: 98.94, Assm: 97.14, PNorm: 111.74, GNorm: 17.41\n",
      "[1000] Beta: 0.002, KL: 97.20, Word: 85.84, Topo: 99.07, Assm: 97.19, PNorm: 112.87, GNorm: 15.76\n",
      "[1100] Beta: 0.002, KL: 94.31, Word: 85.94, Topo: 99.13, Assm: 97.24, PNorm: 114.06, GNorm: 13.79\n",
      "[1200] Beta: 0.002, KL: 94.08, Word: 85.92, Topo: 99.10, Assm: 97.08, PNorm: 115.20, GNorm: 15.33\n",
      "Currently at epoch: 4\n",
      "[1300] Beta: 0.002, KL: 92.39, Word: 86.46, Topo: 99.16, Assm: 97.28, PNorm: 116.38, GNorm: 16.47\n",
      "[1400] Beta: 0.002, KL: 93.73, Word: 86.85, Topo: 99.16, Assm: 97.13, PNorm: 117.37, GNorm: 11.19\n",
      "[1500] Beta: 0.002, KL: 92.36, Word: 86.71, Topo: 99.23, Assm: 97.38, PNorm: 118.39, GNorm: 17.51\n",
      "[1600] Beta: 0.002, KL: 92.44, Word: 87.03, Topo: 99.17, Assm: 97.50, PNorm: 119.36, GNorm: 12.54\n",
      "Currently at epoch: 5\n",
      "[1700] Beta: 0.002, KL: 87.14, Word: 87.22, Topo: 99.21, Assm: 97.23, PNorm: 120.33, GNorm: 15.98\n",
      "[1800] Beta: 0.002, KL: 94.64, Word: 87.75, Topo: 99.28, Assm: 97.19, PNorm: 121.33, GNorm: 11.42\n",
      "[1900] Beta: 0.002, KL: 96.02, Word: 87.84, Topo: 99.28, Assm: 96.96, PNorm: 122.30, GNorm: 13.17\n",
      "[2000] Beta: 0.002, KL: 95.41, Word: 87.88, Topo: 99.19, Assm: 97.22, PNorm: 123.62, GNorm: 13.76\n",
      "Currently at epoch: 6\n",
      "[2100] Beta: 0.002, KL: 91.47, Word: 88.01, Topo: 99.32, Assm: 97.37, PNorm: 124.74, GNorm: 14.01\n",
      "[2200] Beta: 0.002, KL: 93.94, Word: 88.07, Topo: 99.32, Assm: 97.26, PNorm: 125.68, GNorm: 12.22\n",
      "[2300] Beta: 0.002, KL: 93.91, Word: 88.19, Topo: 99.36, Assm: 96.81, PNorm: 126.60, GNorm: 18.29\n",
      "[2400] Beta: 0.002, KL: 89.99, Word: 87.96, Topo: 99.16, Assm: 97.01, PNorm: 127.58, GNorm: 11.28\n",
      "Currently at epoch: 7\n",
      "[2500] Beta: 0.002, KL: 89.07, Word: 88.37, Topo: 99.36, Assm: 97.26, PNorm: 128.37, GNorm: 10.37\n",
      "[2600] Beta: 0.002, KL: 92.56, Word: 88.68, Topo: 99.35, Assm: 97.42, PNorm: 129.09, GNorm: 13.95\n",
      "[2700] Beta: 0.002, KL: 90.26, Word: 88.49, Topo: 99.40, Assm: 96.87, PNorm: 129.81, GNorm: 14.56\n",
      "[2800] Beta: 0.002, KL: 91.08, Word: 88.71, Topo: 99.38, Assm: 96.94, PNorm: 130.41, GNorm: 10.82\n",
      "Currently at epoch: 8\n",
      "[2900] Beta: 0.002, KL: 87.18, Word: 88.85, Topo: 99.41, Assm: 97.59, PNorm: 131.17, GNorm: 11.14\n",
      "[3000] Beta: 0.002, KL: 90.31, Word: 88.84, Topo: 99.33, Assm: 97.47, PNorm: 131.82, GNorm: 11.53\n",
      "[3100] Beta: 0.002, KL: 89.54, Word: 88.95, Topo: 99.41, Assm: 96.93, PNorm: 132.51, GNorm: 11.48\n",
      "[3200] Beta: 0.002, KL: 89.78, Word: 89.08, Topo: 99.24, Assm: 97.25, PNorm: 133.31, GNorm: 15.04\n",
      "Currently at epoch: 9\n",
      "[3300] Beta: 0.002, KL: 83.13, Word: 88.90, Topo: 99.39, Assm: 97.29, PNorm: 134.07, GNorm: 11.00\n",
      "[3400] Beta: 0.002, KL: 93.09, Word: 89.25, Topo: 99.40, Assm: 97.44, PNorm: 134.73, GNorm: 10.81\n",
      "[3500] Beta: 0.002, KL: 89.43, Word: 89.18, Topo: 99.37, Assm: 96.81, PNorm: 135.67, GNorm: 12.29\n",
      "[3600] Beta: 0.002, KL: 96.38, Word: 89.34, Topo: 99.39, Assm: 97.37, PNorm: 136.33, GNorm: 15.49\n",
      "Currently at epoch: 10\n",
      "[3700] Beta: 0.002, KL: 93.43, Word: 89.47, Topo: 99.46, Assm: 97.26, PNorm: 137.13, GNorm: 14.76\n",
      "[3800] Beta: 0.002, KL: 93.89, Word: 89.67, Topo: 99.43, Assm: 97.24, PNorm: 137.88, GNorm: 12.89\n",
      "[3900] Beta: 0.002, KL: 91.09, Word: 89.55, Topo: 99.45, Assm: 96.95, PNorm: 138.61, GNorm: 12.33\n",
      "[4000] Beta: 0.002, KL: 96.95, Word: 89.62, Topo: 99.40, Assm: 97.15, PNorm: 139.27, GNorm: 8.95\n",
      "Currently at epoch: 11\n",
      "[4100] Beta: 0.002, KL: 86.77, Word: 89.27, Topo: 99.42, Assm: 97.10, PNorm: 140.31, GNorm: 12.98\n",
      "[4200] Beta: 0.002, KL: 97.24, Word: 89.70, Topo: 99.42, Assm: 97.39, PNorm: 141.26, GNorm: 13.55\n",
      "[4300] Beta: 0.002, KL: 94.01, Word: 89.84, Topo: 99.40, Assm: 96.99, PNorm: 142.00, GNorm: 12.42\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-523eb6dfc491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtotal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_div\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/port-to-botorch/rafa-pred-model/jtnn/jtnn_vae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_batch, beta)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_jtenc_holder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mpn_holder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_jtmpn_holder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mx_tree_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tree_mess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mol_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_jtenc_holder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mpn_holder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mz_tree_vecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tree_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mz_mol_vecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmol_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mol_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/port-to-botorch/rafa-pred-model/jtnn/jtnn_vae.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, jtenc_holder, mpn_holder)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjtenc_holder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpn_holder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mtree_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_mess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjtnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjtenc_holder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mmol_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmpn_holder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtree_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_mess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol_vecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/port-to-botorch/rafa-pred-model/jtnn/jtnn_enc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, fnode, fmess, node_graph, mess_graph, scope)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnode_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmess_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmess_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmess_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mfnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epoch):\n",
    "    print(f\"Currently at epoch: {epoch+1}\")\n",
    "    loader = MolTreeFolder(train_path, vocab, args.batch_size, num_workers=4)\n",
    "    for batch in loader:\n",
    "        total_step += 1\n",
    "        model.zero_grad()\n",
    "        loss, kl_div, wacc, tacc, sacc = model(batch, beta)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), args.clip_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        meters = meters + np.array([kl_div, wacc * 100, tacc * 100, sacc * 100])\n",
    "\n",
    "        if total_step % args.print_iter == 0:\n",
    "            meters /= args.print_iter\n",
    "            print((\"[%d] Beta: %.3f, KL: %.2f, Word: %.2f, Topo: %.2f, Assm: %.2f, PNorm: %.2f, GNorm: %.2f\" % (total_step, beta, meters[0], meters[1], meters[2], meters[3], param_norm(model), grad_norm(model))))\n",
    "            sys.stdout.flush()\n",
    "            meters *= 0\n",
    "\n",
    "        if total_step % args.save_iter == 0:\n",
    "            torch.save(model.state_dict(), args.save_dir + \"/model.iter-\" + str(total_step))\n",
    "\n",
    "        if total_step % args.anneal_iter == 0:\n",
    "            scheduler.step()\n",
    "            print((\"learning rate: %.6f\" % scheduler.get_lr()[0]))\n",
    "\n",
    "        if total_step % args.kl_anneal_iter == 0 and total_step >= args.warmup:\n",
    "            beta = min(args.max_beta, beta + args.step_beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374af8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
